{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nz0xUXzeLaqB"
   },
   "source": [
    "# MicroYOLO v2 - ESP32-CAM için Geliştirilmiş YOLO\n",
    "\n",
    "**Yenilikler:**\n",
    "- Depthwise Separable Convolutions (MobileNet tarzı) - daha az parametre\n",
    "- Ağır Data Augmentation - gerçek el yazısına benzer eğitim\n",
    "- Daha iyi Loss fonksiyonu\n",
    "- ST YOLO LC ve YOLOv5-nano'dan ilham alan mimari\n",
    "\n",
    "**Hedef:**\n",
    "- Model boyutu: < 150KB (INT8)\n",
    "- Giriş: 96x96x3\n",
    "- Çıkış: 6x6 grid, 10 sınıf (0-9 rakamları)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1767986421365,
     "user": {
      "displayName": "Kerem Ergünay",
      "userId": "05365933786854418126"
     },
     "user_tz": -180
    },
    "id": "qr_m_GxXLaqC",
    "outputId": "d096d1ec-37b5-4d9b-b730-dafe66652cd2"
   },
   "outputs": [],
   "source": [
    "# GPU kontrolu\n",
    "import tensorflow as tf\n",
    "print('TensorFlow:', tf.__version__)\n",
    "print('GPU:', tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1767986421390,
     "user": {
      "displayName": "Kerem Ergünay",
      "userId": "05365933786854418126"
     },
     "user_tz": -180
    },
    "id": "zs8M2H9rLaqD",
    "outputId": "7987fb1e-7e53-4ab8-850c-5591340f51f3"
   },
   "outputs": [],
   "source": [
    "# Gerekli kutuphaneler\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import random\n",
    "from PIL import Image, ImageDraw, ImageFilter, ImageEnhance\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Sabitler\n",
    "IMG_SIZE = 96\n",
    "GRID_SIZE = 6\n",
    "NUM_CLASSES = 10\n",
    "OUTPUT_PER_CELL = 5 + NUM_CLASSES  # 15\n",
    "\n",
    "# Egitim ayarlari - UZUN EGITIM (daha iyi dogruluk icin)\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 400          # 200 -> 400 (2x daha uzun)\n",
    "LEARNING_RATE = 0.001\n",
    "TRAIN_SAMPLES = 40000  # 20000 -> 40000 (2x daha fazla veri)\n",
    "VAL_SAMPLES = 8000     # 4000 -> 8000\n",
    "\n",
    "# Tahmini egitim suresi: ~30-45 dakika (Colab GPU ile)\n",
    "\n",
    "print(f'Grid: {GRID_SIZE}x{GRID_SIZE}, Output per cell: {OUTPUT_PER_CELL}')\n",
    "print(f'Train: {TRAIN_SAMPLES}, Val: {VAL_SAMPLES}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 335,
     "status": "ok",
     "timestamp": 1767986421715,
     "user": {
      "displayName": "Kerem Ergünay",
      "userId": "05365933786854418126"
     },
     "user_tz": -180
    },
    "id": "BR6ZeNn2LaqD",
    "outputId": "0d20723b-e002-49a4-8651-d019c91d5f7f"
   },
   "outputs": [],
   "source": [
    "# MNIST yukle\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "(mnist_x_train, mnist_y_train), (mnist_x_test, mnist_y_test) = mnist.load_data()\n",
    "print(f'MNIST Train: {mnist_x_train.shape}')\n",
    "\n",
    "# Sinif bazli ayirma\n",
    "mnist_by_class = {}\n",
    "for i in range(10):\n",
    "    mnist_by_class[i] = mnist_x_train[mnist_y_train == i]\n",
    "    print(f'  Sinif {i}: {len(mnist_by_class[i])} ornek')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1767986421727,
     "user": {
      "displayName": "Kerem Ergünay",
      "userId": "05365933786854418126"
     },
     "user_tz": -180
    },
    "id": "i__MXGbELaqE",
    "outputId": "a9bc4d4a-36da-4d6b-c788-1a633b03e1de"
   },
   "outputs": [],
   "source": [
    "# ==================== AGIR DATA AUGMENTATION ====================\n",
    "\n",
    "def random_perspective(img, strength=0.1):\n",
    "    h, w = img.shape[:2]\n",
    "    pts1 = np.float32([[0, 0], [w, 0], [0, h], [w, h]])\n",
    "    offset = int(w * strength)\n",
    "    pts2 = np.float32([\n",
    "        [random.randint(0, offset), random.randint(0, offset)],\n",
    "        [w - random.randint(0, offset), random.randint(0, offset)],\n",
    "        [random.randint(0, offset), h - random.randint(0, offset)],\n",
    "        [w - random.randint(0, offset), h - random.randint(0, offset)]\n",
    "    ])\n",
    "    M = cv2.getPerspectiveTransform(pts1, pts2)\n",
    "    return cv2.warpPerspective(img, M, (w, h), borderValue=255)\n",
    "\n",
    "def random_rotation(img, max_angle=30):\n",
    "    angle = random.uniform(-max_angle, max_angle)\n",
    "    h, w = img.shape[:2]\n",
    "    M = cv2.getRotationMatrix2D((w/2, h/2), angle, 1.0)\n",
    "    return cv2.warpAffine(img, M, (w, h), borderValue=255)\n",
    "\n",
    "def random_blur(img):\n",
    "    if random.random() < 0.3:\n",
    "        kernel = random.choice([1, 3])\n",
    "        return cv2.GaussianBlur(img, (kernel, kernel), 0)\n",
    "    return img\n",
    "\n",
    "def random_noise(img, strength=10):\n",
    "    if random.random() < 0.4:\n",
    "        noise = np.random.normal(0, strength, img.shape).astype(np.int16)\n",
    "        return np.clip(img.astype(np.int16) + noise, 0, 255).astype(np.uint8)\n",
    "    return img\n",
    "\n",
    "def random_brightness_contrast(img):\n",
    "    alpha = random.uniform(0.7, 1.3)\n",
    "    beta = random.randint(-30, 30)\n",
    "    return np.clip(alpha * img + beta, 0, 255).astype(np.uint8)\n",
    "\n",
    "def random_erode_dilate(img):\n",
    "    if random.random() < 0.3:\n",
    "        kernel = np.ones((2, 2), np.uint8)\n",
    "        if random.random() < 0.5:\n",
    "            return cv2.erode(img, kernel, iterations=1)\n",
    "        else:\n",
    "            return cv2.dilate(img, kernel, iterations=1)\n",
    "    return img\n",
    "\n",
    "def augment_digit(digit_img):\n",
    "    if random.random() < 0.3:\n",
    "        digit_img = random_perspective(digit_img, 0.15)\n",
    "    if random.random() < 0.5:\n",
    "        digit_img = random_rotation(digit_img, 25)\n",
    "    digit_img = random_erode_dilate(digit_img)\n",
    "    return digit_img\n",
    "\n",
    "print('Augmentation fonksiyonlari tanimlandi.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1767986421733,
     "user": {
      "displayName": "Kerem Ergünay",
      "userId": "05365933786854418126"
     },
     "user_tz": -180
    },
    "id": "3XppE-IoLaqE",
    "outputId": "e818d447-7061-48b7-9351-fd1dea1113a5"
   },
   "outputs": [],
   "source": [
    "# ==================== GERCEKCI GORUNTU OLUSTURMA ====================\n",
    "# GERCEK DUNYA: Koyu rakamlar ACIK kagit uzerinde (kalem/tukenmez kalem)\n",
    "\n",
    "def generate_realistic_sample(img_size=96, max_digits=3):\n",
    "    # Arka plan: ACIK kagit tonlari (beyaz/krem)\n",
    "    bg_choices = [\n",
    "        random.randint(220, 255),  # Beyaz kagit\n",
    "        random.randint(200, 235),  # Krem kagit\n",
    "        random.randint(190, 220),  # Eski kagit\n",
    "    ]\n",
    "    bg_color = random.choice(bg_choices)\n",
    "    img = np.full((img_size, img_size), bg_color, dtype=np.uint8)\n",
    "\n",
    "    # Kagit texture (hafif grainli)\n",
    "    if random.random() < 0.6:\n",
    "        noise = np.random.normal(0, 4, img.shape).astype(np.int16)\n",
    "        img = np.clip(img.astype(np.int16) + noise, 0, 255).astype(np.uint8)\n",
    "\n",
    "    labels = []\n",
    "    num_digits = random.randint(1, max_digits)\n",
    "    placed_boxes = []\n",
    "\n",
    "    for _ in range(num_digits):\n",
    "        digit_class = random.randint(0, 9)\n",
    "        digit_idx = random.randint(0, len(mnist_by_class[digit_class]) - 1)\n",
    "        digit = mnist_by_class[digit_class][digit_idx].copy()\n",
    "\n",
    "        digit = augment_digit(digit)\n",
    "\n",
    "        scale = random.uniform(0.25, 0.55)\n",
    "        new_size = int(28 * scale * img_size / 28)\n",
    "        new_size = max(12, min(new_size, img_size - 4))\n",
    "\n",
    "        digit_resized = cv2.resize(digit, (new_size, new_size), interpolation=cv2.INTER_LINEAR)\n",
    "        # MNIST: beyaz rakam siyah arka plan -> mask olarak kullan (255=rakam alani)\n",
    "\n",
    "        # Murekkkep/kalem rengi: KOYU (siyah, mavi, koyu gri)\n",
    "        ink_colors = [\n",
    "            random.randint(0, 40),    # Siyah kalem\n",
    "            random.randint(10, 50),   # Koyu gri\n",
    "            random.randint(0, 30),    # Tukenmez kalem\n",
    "        ]\n",
    "        ink_color = random.choice(ink_colors)\n",
    "\n",
    "        max_attempts = 20\n",
    "        for attempt in range(max_attempts):\n",
    "            x = random.randint(0, img_size - new_size)\n",
    "            y = random.randint(0, img_size - new_size)\n",
    "\n",
    "            new_box = (x, y, x + new_size, y + new_size)\n",
    "            overlap = False\n",
    "            for box in placed_boxes:\n",
    "                if not (new_box[2] < box[0] or new_box[0] > box[2] or new_box[3] < box[1] or new_box[1] > box[3]):\n",
    "                    overlap = True\n",
    "                    break\n",
    "            if not overlap:\n",
    "                break\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        placed_boxes.append(new_box)\n",
    "\n",
    "        roi = img[y:y+new_size, x:x+new_size]\n",
    "        # mask: MNIST'ten direkt kullan (beyaz=rakam alani=yuksek deger)\n",
    "        mask = digit_resized.astype(np.float32) / 255.0\n",
    "        # Blending: mask yuksek (rakam) -> koyu ink, mask dusuk (arka plan) -> acik kagit\n",
    "        blended = (roi * (1.0 - mask) + ink_color * mask).astype(np.uint8)\n",
    "        img[y:y+new_size, x:x+new_size] = blended\n",
    "\n",
    "        x_center = (x + new_size / 2) / img_size\n",
    "        y_center = (y + new_size / 2) / img_size\n",
    "        width = new_size / img_size\n",
    "        height = new_size / img_size\n",
    "        labels.append([digit_class, x_center, y_center, width, height])\n",
    "\n",
    "    img = random_blur(img)\n",
    "    img = random_noise(img, 8)\n",
    "    img = random_brightness_contrast(img)\n",
    "\n",
    "    return img, labels\n",
    "\n",
    "def labels_to_yolo_output(labels, grid_size=6, num_classes=10):\n",
    "    output = np.zeros((grid_size, grid_size, 5 + num_classes), dtype=np.float32)\n",
    "    for label in labels:\n",
    "        class_id, x_center, y_center, width, height = label\n",
    "        grid_x = min(int(x_center * grid_size), grid_size - 1)\n",
    "        grid_y = min(int(y_center * grid_size), grid_size - 1)\n",
    "        x_offset = x_center * grid_size - grid_x\n",
    "        y_offset = y_center * grid_size - grid_y\n",
    "        if output[grid_y, grid_x, 4] == 0:\n",
    "            output[grid_y, grid_x, 0] = x_offset\n",
    "            output[grid_y, grid_x, 1] = y_offset\n",
    "            output[grid_y, grid_x, 2] = width\n",
    "            output[grid_y, grid_x, 3] = height\n",
    "            output[grid_y, grid_x, 4] = 1.0\n",
    "            output[grid_y, grid_x, 5 + int(class_id)] = 1.0\n",
    "    return output\n",
    "\n",
    "print('Goruntu olusturucu tanimlandi.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 610
    },
    "executionInfo": {
     "elapsed": 631,
     "status": "ok",
     "timestamp": 1767986422367,
     "user": {
      "displayName": "Kerem Ergünay",
      "userId": "05365933786854418126"
     },
     "user_tz": -180
    },
    "id": "DQP1KgH8LaqF",
    "outputId": "33c9cad1-6320-4618-a9c2-fee4bc0a2b61"
   },
   "outputs": [],
   "source": [
    "# Ornek goruntuler goster\n",
    "fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
    "for ax in axes.flatten():\n",
    "    img, labels = generate_realistic_sample()\n",
    "    ax.imshow(img, cmap='gray')\n",
    "    ax.axis('off')\n",
    "    for label in labels:\n",
    "        cls, xc, yc, w, h = label\n",
    "        x1 = int((xc - w/2) * IMG_SIZE)\n",
    "        y1 = int((yc - h/2) * IMG_SIZE)\n",
    "        rect = plt.Rectangle((x1, y1), int(w*IMG_SIZE), int(h*IMG_SIZE), fill=False, color='red', linewidth=2)\n",
    "        ax.add_patch(rect)\n",
    "        ax.text(x1, y1-2, str(int(cls)), color='red', fontsize=10, weight='bold')\n",
    "plt.suptitle('Gercekci Egitim Verileri - KOYU rakam ACIK kagit (Gercek Dunya)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 31780,
     "status": "ok",
     "timestamp": 1767986454156,
     "user": {
      "displayName": "Kerem Ergünay",
      "userId": "05365933786854418126"
     },
     "user_tz": -180
    },
    "id": "0pVwC2wXLaqF",
    "outputId": "929283c9-fb7f-4a75-9494-269984623c5b"
   },
   "outputs": [],
   "source": [
    "# Veri seti olustur\n",
    "print('Egitim verisi olusturuluyor...')\n",
    "X_train, y_train = [], []\n",
    "for i in range(TRAIN_SAMPLES):\n",
    "    if i % 5000 == 0: print(f'  {i}/{TRAIN_SAMPLES}')\n",
    "    img, labels = generate_realistic_sample(IMG_SIZE, max_digits=3)\n",
    "    X_train.append(img)\n",
    "    y_train.append(labels_to_yolo_output(labels, GRID_SIZE, NUM_CLASSES))\n",
    "\n",
    "X_train = np.array(X_train, dtype=np.float32) / 255.0\n",
    "y_train = np.array(y_train, dtype=np.float32)\n",
    "X_train = np.stack([X_train, X_train, X_train], axis=-1)\n",
    "\n",
    "print('\\nValidation verisi olusturuluyor...')\n",
    "X_val, y_val = [], []\n",
    "for i in range(VAL_SAMPLES):\n",
    "    if i % 1000 == 0: print(f'  {i}/{VAL_SAMPLES}')\n",
    "    img, labels = generate_realistic_sample(IMG_SIZE, max_digits=3)\n",
    "    X_val.append(img)\n",
    "    y_val.append(labels_to_yolo_output(labels, GRID_SIZE, NUM_CLASSES))\n",
    "\n",
    "X_val = np.array(X_val, dtype=np.float32) / 255.0\n",
    "X_val = np.stack([X_val, X_val, X_val], axis=-1)\n",
    "y_val = np.array(y_val, dtype=np.float32)\n",
    "\n",
    "print(f'\\nX_train: {X_train.shape}, y_train: {y_train.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 1886,
     "status": "ok",
     "timestamp": 1767986456040,
     "user": {
      "displayName": "Kerem Ergünay",
      "userId": "05365933786854418126"
     },
     "user_tz": -180
    },
    "id": "dYEfSEM-LaqF",
    "outputId": "3da4334f-db2b-4e27-f324-d4386eb15402"
   },
   "outputs": [],
   "source": [
    "# ==================== MICROYOLO v2 MODEL ====================\n",
    "# Depthwise Separable Convolutions ile parametre azaltma\n",
    "\n",
    "def depthwise_separable_conv(x, filters, kernel_size=3, strides=1, name_prefix=''):\n",
    "    x = layers.DepthwiseConv2D(kernel_size, strides=strides, padding='same', use_bias=False, name=f'{name_prefix}_dw')(x)\n",
    "    x = layers.BatchNormalization(name=f'{name_prefix}_dw_bn')(x)\n",
    "    x = layers.ReLU(6.0, name=f'{name_prefix}_dw_relu')(x)\n",
    "    x = layers.Conv2D(filters, 1, padding='same', use_bias=False, name=f'{name_prefix}_pw')(x)\n",
    "    x = layers.BatchNormalization(name=f'{name_prefix}_pw_bn')(x)\n",
    "    x = layers.ReLU(6.0, name=f'{name_prefix}_pw_relu')(x)\n",
    "    return x\n",
    "\n",
    "def conv_block(x, filters, kernel_size=3, strides=1, name_prefix=''):\n",
    "    x = layers.Conv2D(filters, kernel_size, strides=strides, padding='same', use_bias=False, name=f'{name_prefix}_conv')(x)\n",
    "    x = layers.BatchNormalization(name=f'{name_prefix}_bn')(x)\n",
    "    x = layers.ReLU(6.0, name=f'{name_prefix}_relu')(x)\n",
    "    return x\n",
    "\n",
    "class YOLOOutputLayer(layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def call(self, x):\n",
    "        bbox_conf = tf.sigmoid(x[..., :5])\n",
    "        classes = tf.nn.softmax(x[..., 5:])\n",
    "        return tf.concat([bbox_conf, classes], axis=-1)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape\n",
    "\n",
    "def create_micro_yolo_v2(input_shape=(96, 96, 3), grid_size=6, num_classes=10):\n",
    "    inputs = keras.Input(shape=input_shape, name='input')\n",
    "\n",
    "    # Stem\n",
    "    x = conv_block(inputs, 16, 3, strides=2, name_prefix='stem')  # 48x48\n",
    "\n",
    "    # Stage 1\n",
    "    x = depthwise_separable_conv(x, 32, name_prefix='stage1')\n",
    "    x = layers.MaxPooling2D(2, name='pool1')(x)  # 24x24\n",
    "\n",
    "    # Stage 2\n",
    "    x = depthwise_separable_conv(x, 64, name_prefix='stage2_1')\n",
    "    x = depthwise_separable_conv(x, 64, name_prefix='stage2_2')\n",
    "    x = layers.MaxPooling2D(2, name='pool2')(x)  # 12x12\n",
    "\n",
    "    # Stage 3\n",
    "    x = depthwise_separable_conv(x, 128, name_prefix='stage3_1')\n",
    "    x = depthwise_separable_conv(x, 128, name_prefix='stage3_2')\n",
    "    x = layers.MaxPooling2D(2, name='pool3')(x)  # 6x6\n",
    "\n",
    "    # Detection Head\n",
    "    x = depthwise_separable_conv(x, 128, name_prefix='head1')\n",
    "    x = conv_block(x, 64, kernel_size=1, name_prefix='head2')\n",
    "\n",
    "    output_channels = 5 + num_classes\n",
    "    x = layers.Conv2D(output_channels, 1, padding='same', name='output_conv')(x)\n",
    "    outputs = YOLOOutputLayer(name='yolo_output')(x)\n",
    "\n",
    "    return Model(inputs, outputs, name='MicroYOLO_v2')\n",
    "\n",
    "model = create_micro_yolo_v2()\n",
    "model.summary()\n",
    "print(f'\\nToplam parametre: {model.count_params():,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1767986456061,
     "user": {
      "displayName": "Kerem Ergünay",
      "userId": "05365933786854418126"
     },
     "user_tz": -180
    },
    "id": "UFQYovuzLaqG",
    "outputId": "0043153c-1aa8-4bb9-b7c3-e6a53a1e1246"
   },
   "outputs": [],
   "source": [
    "# YOLO Loss\n",
    "def yolo_loss_v2(y_true, y_pred):\n",
    "    obj_mask = y_true[..., 4:5]\n",
    "    noobj_mask = 1.0 - obj_mask\n",
    "\n",
    "    lambda_coord = 5.0\n",
    "    lambda_noobj = 0.5\n",
    "    lambda_class = 1.0\n",
    "\n",
    "    xy_loss = tf.reduce_sum(obj_mask * tf.square(y_true[..., :2] - y_pred[..., :2]))\n",
    "\n",
    "    wh_true = tf.sqrt(tf.abs(y_true[..., 2:4]) + 1e-6)\n",
    "    wh_pred = tf.sqrt(tf.abs(y_pred[..., 2:4]) + 1e-6)\n",
    "    wh_loss = tf.reduce_sum(obj_mask * tf.square(wh_true - wh_pred))\n",
    "\n",
    "    conf_pred = tf.clip_by_value(y_pred[..., 4:5], 1e-7, 1.0 - 1e-7)\n",
    "    conf_loss_obj = -tf.reduce_sum(obj_mask * tf.math.log(conf_pred))\n",
    "    conf_loss_noobj = -tf.reduce_sum(noobj_mask * tf.math.log(1.0 - conf_pred))\n",
    "\n",
    "    class_true = y_true[..., 5:]\n",
    "    class_pred = tf.clip_by_value(y_pred[..., 5:], 1e-7, 1.0 - 1e-7)\n",
    "    class_loss = -tf.reduce_sum(obj_mask * class_true * tf.math.log(class_pred))\n",
    "\n",
    "    total = lambda_coord * (xy_loss + wh_loss) + conf_loss_obj + lambda_noobj * conf_loss_noobj + lambda_class * class_loss\n",
    "    return total / tf.cast(tf.shape(y_true)[0], tf.float32)\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=LEARNING_RATE), loss=yolo_loss_v2)\n",
    "print('Model derlendi.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s9j3HUr1LaqG",
    "outputId": "c5e813d9-c243-4f71-a074-9d93a34768ac"
   },
   "outputs": [],
   "source": [
    "# Egitim - Gelismis callbacks\n",
    "callbacks = [\n",
    "    ModelCheckpoint('micro_yolo_v2_best.keras', monitor='val_loss', save_best_only=True, verbose=1),\n",
    "    EarlyStopping(monitor='val_loss', patience=50, restore_best_weights=True, verbose=1),  # Daha sabirli\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=15, min_lr=1e-7, verbose=1),  # Daha yavas azalt\n",
    "    keras.callbacks.LearningRateScheduler(\n",
    "        lambda epoch: LEARNING_RATE * (0.5 * (1 + np.cos(np.pi * epoch / EPOCHS))),  # Cosine decay\n",
    "        verbose=0\n",
    "    )\n",
    "]\n",
    "\n",
    "print(f'Egitim basliyor... ({EPOCHS} epoch, {TRAIN_SAMPLES} ornek)')\n",
    "print('Tahmini sure: ~30-45 dakika (Colab T4 GPU ile)')\n",
    "history = model.fit(X_train, y_train, validation_data=(X_val, y_val),\n",
    "                    batch_size=BATCH_SIZE, epochs=EPOCHS, callbacks=callbacks, verbose=1)\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(history.history['loss'], label='Train')\n",
    "plt.plot(history.history['val_loss'], label='Val')\n",
    "plt.xlabel('Epoch'); plt.ylabel('Loss'); plt.legend(); plt.grid(True)\n",
    "plt.title('MicroYOLO v2 Egitim')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8-2JJxr2LaqH"
   },
   "outputs": [],
   "source": [
    "# FLOAT32 Test\n",
    "def decode_predictions(pred, conf_threshold=0.3, img_size=96, grid_size=6):\n",
    "    detections = []\n",
    "    for gy in range(grid_size):\n",
    "        for gx in range(grid_size):\n",
    "            conf = pred[gy, gx, 4]\n",
    "            if conf > conf_threshold:\n",
    "                x_offset, y_offset = pred[gy, gx, 0], pred[gy, gx, 1]\n",
    "                w, h = pred[gy, gx, 2], pred[gy, gx, 3]\n",
    "                x_center = (gx + x_offset) / grid_size\n",
    "                y_center = (gy + y_offset) / grid_size\n",
    "                x1 = int((x_center - w/2) * img_size)\n",
    "                y1 = int((y_center - h/2) * img_size)\n",
    "                x2 = int((x_center + w/2) * img_size)\n",
    "                y2 = int((y_center + h/2) * img_size)\n",
    "                class_probs = pred[gy, gx, 5:]\n",
    "                class_id = np.argmax(class_probs)\n",
    "                final_conf = conf * class_probs[class_id]\n",
    "                if final_conf > conf_threshold:\n",
    "                    detections.append([class_id, final_conf, x1, y1, x2, y2])\n",
    "    return detections\n",
    "\n",
    "print('=== FLOAT32 Model Test (1000 ornek) ===')\n",
    "class_correct = {i: 0 for i in range(10)}\n",
    "class_total = {i: 0 for i in range(10)}\n",
    "\n",
    "for _ in range(1000):  # Daha fazla test ornegi\n",
    "    img, labels = generate_realistic_sample(max_digits=1)\n",
    "    if len(labels) == 0: continue\n",
    "    true_class = int(labels[0][0])\n",
    "    class_total[true_class] += 1\n",
    "    img_rgb = np.stack([img, img, img], axis=-1).astype(np.float32) / 255.0\n",
    "    pred = model.predict(np.expand_dims(img_rgb, 0), verbose=0)[0]\n",
    "    dets = decode_predictions(pred, 0.2)\n",
    "    if len(dets) > 0 and int(dets[0][0]) == true_class:\n",
    "        class_correct[true_class] += 1\n",
    "\n",
    "print('\\nFLOAT32 Sinif Basina Dogruluk:')\n",
    "for i in range(10):\n",
    "    if class_total[i] > 0:\n",
    "        print(f'  Rakam {i}: {class_correct[i]}/{class_total[i]} = {100*class_correct[i]/class_total[i]:.1f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bp48wtbaLaqH"
   },
   "outputs": [],
   "source": [
    "# INT8 Quantization\n",
    "model = keras.models.load_model('micro_yolo_v2_best.keras',\n",
    "                                 custom_objects={'yolo_loss_v2': yolo_loss_v2, 'YOLOOutputLayer': YOLOOutputLayer})\n",
    "\n",
    "def representative_dataset_balanced():\n",
    "    samples_per_class = 100\n",
    "    for digit in range(10):\n",
    "        for _ in range(samples_per_class):\n",
    "            img, _ = generate_realistic_sample(max_digits=1)\n",
    "            img_rgb = np.stack([img, img, img], axis=-1).astype(np.float32) / 255.0\n",
    "            yield [np.expand_dims(img_rgb, 0)]\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_dataset_balanced\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.inference_input_type = tf.int8\n",
    "converter.inference_output_type = tf.int8\n",
    "\n",
    "print('TFLite INT8 donusumu...')\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "with open('micro_yolo_v2_int8.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)\n",
    "print(f'TFLite model: {len(tflite_model) / 1024:.1f} KB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iHAVQJD7LaqH"
   },
   "outputs": [],
   "source": [
    "# INT8 Model Test - Kapsamli\n",
    "print('=== INT8 Model Test (1000 ornek) ===')\n",
    "interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "input_scale = input_details[0]['quantization'][0]\n",
    "input_zp = input_details[0]['quantization'][1]\n",
    "output_scale = output_details[0]['quantization'][0]\n",
    "output_zp = output_details[0]['quantization'][1]\n",
    "\n",
    "print(f'Input: {input_details[0][\"shape\"]}, scale={input_scale:.6f}, zp={input_zp}')\n",
    "print(f'Output: {output_details[0][\"shape\"]}, scale={output_scale:.6f}, zp={output_zp}')\n",
    "\n",
    "int8_correct = {i: 0 for i in range(10)}\n",
    "int8_total = {i: 0 for i in range(10)}\n",
    "\n",
    "for _ in range(1000):  # Daha fazla test ornegi\n",
    "    img, labels = generate_realistic_sample(max_digits=1)\n",
    "    if len(labels) == 0: continue\n",
    "    true_class = int(labels[0][0])\n",
    "    int8_total[true_class] += 1\n",
    "\n",
    "    img_rgb = np.stack([img, img, img], axis=-1).astype(np.float32) / 255.0\n",
    "    img_int8 = ((img_rgb / input_scale) + input_zp).astype(np.int8)\n",
    "    input_data = img_int8.reshape(1, 96, 96, 3)\n",
    "\n",
    "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "    interpreter.invoke()\n",
    "\n",
    "    output = interpreter.get_tensor(output_details[0]['index'])[0]\n",
    "    output_float = (output.astype(np.float32) - output_zp) * output_scale\n",
    "\n",
    "    best_conf, best_cls = -1, -1\n",
    "    for gy in range(6):\n",
    "        for gx in range(6):\n",
    "            conf = output_float[gy, gx, 4]\n",
    "            if conf > best_conf:\n",
    "                best_conf = conf\n",
    "                best_cls = np.argmax(output_float[gy, gx, 5:15])\n",
    "\n",
    "    if best_cls == true_class:\n",
    "        int8_correct[true_class] += 1\n",
    "\n",
    "print('\\nINT8 Sinif Basina Dogruluk:')\n",
    "total_c, total_s = 0, 0\n",
    "for i in range(10):\n",
    "    if int8_total[i] > 0:\n",
    "        print(f'  Rakam {i}: {int8_correct[i]}/{int8_total[i]} = {100*int8_correct[i]/int8_total[i]:.1f}%')\n",
    "        total_c += int8_correct[i]\n",
    "        total_s += int8_total[i]\n",
    "print(f'\\nToplam: {total_c}/{total_s} = {100*total_c/total_s:.1f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KeEKbQ7VLaqH"
   },
   "outputs": [],
   "source": [
    "# C Header olustur\n",
    "def create_c_header(tflite_path, header_path):\n",
    "    with open(tflite_path, 'rb') as f:\n",
    "        model_data = f.read()\n",
    "\n",
    "    interp = tf.lite.Interpreter(model_path=tflite_path)\n",
    "    interp.allocate_tensors()\n",
    "    inp = interp.get_input_details()[0]\n",
    "    out = interp.get_output_details()[0]\n",
    "\n",
    "    with open(header_path, 'w') as f:\n",
    "        f.write('// MicroYOLO v2 for ESP32-CAM - Auto-generated\\n')\n",
    "        f.write(f'// Model size: {len(model_data)} bytes\\n\\n')\n",
    "        f.write('#ifndef MICRO_YOLO_MODEL_H\\n#define MICRO_YOLO_MODEL_H\\n\\n')\n",
    "        f.write('#include <stdint.h>\\n\\n')\n",
    "        f.write('#define MICRO_YOLO_INPUT_SIZE 96\\n')\n",
    "        f.write('#define MICRO_YOLO_GRID_SIZE 6\\n')\n",
    "        f.write('#define MICRO_YOLO_NUM_CLASSES 10\\n\\n')\n",
    "        f.write(f'const float input_scale = {inp[\"quantization\"][0]}f;\\n')\n",
    "        f.write(f'const int input_zero_point = {inp[\"quantization\"][1]};\\n')\n",
    "        f.write(f'const float output_scale = {out[\"quantization\"][0]}f;\\n')\n",
    "        f.write(f'const int output_zero_point = {out[\"quantization\"][1]};\\n\\n')\n",
    "        f.write('const char* digit_labels[] = {\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\"};\\n')\n",
    "        f.write('const int NUM_CLASSES = 10;\\n\\n')\n",
    "        f.write(f'const unsigned int digit_model_len = {len(model_data)};\\n')\n",
    "        f.write('alignas(8) const unsigned char digit_model[] = {\\n')\n",
    "        for i, byte in enumerate(model_data):\n",
    "            if i % 16 == 0: f.write('  ')\n",
    "            f.write(f'0x{byte:02x},')\n",
    "            if i % 16 == 15: f.write('\\n')\n",
    "        f.write('\\n};\\n\\n#endif\\n')\n",
    "\n",
    "    print(f'Header: {header_path} ({len(model_data)/1024:.1f} KB)')\n",
    "\n",
    "create_c_header('micro_yolo_v2_int8.tflite', 'micro_yolo_model.h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OtmyIboZLaqI"
   },
   "outputs": [],
   "source": [
    "# Dosyalari kaydet (Kaggle/Colab uyumlu)\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "# Kaggle icin output klasorune kopyala\n",
    "if os.path.exists('/kaggle/working'):\n",
    "    # Kaggle ortami\n",
    "    shutil.copy('micro_yolo_model.h', '/kaggle/working/micro_yolo_model.h')\n",
    "    shutil.copy('micro_yolo_v2_int8.tflite', '/kaggle/working/micro_yolo_v2_int8.tflite')\n",
    "    print('Dosyalar /kaggle/working/ klasorune kaydedildi.')\n",
    "    print('Kaggle Output sekmesinden indirebilirsin!')\n",
    "else:\n",
    "    # Colab ortami\n",
    "    try:\n",
    "        from google.colab import files\n",
    "        files.download('micro_yolo_model.h')\n",
    "        files.download('micro_yolo_v2_int8.tflite')\n",
    "        print('Dosyalar indiriliyor...')\n",
    "    except:\n",
    "        print('Dosyalar mevcut dizinde kaydedildi.')\n",
    "\n",
    "print('\\nTamamlandi! micro_yolo_model.h dosyasini ESP32 projesine kopyala.')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
