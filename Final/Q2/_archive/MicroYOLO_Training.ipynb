{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# MicroYOLO - ESP32-CAM icin Ultra Hafif YOLO\n",
        "\n",
        "Bu notebook, ESP32-CAM'de calisabilecek cok kucuk bir YOLO modeli egitir.\n",
        "\n",
        "**Ozellikler:**\n",
        "- Girdi: 96x96x3 RGB\n",
        "- Model boyutu: < 500KB (INT8)\n",
        "- YOLO tarz cikti (bbox + sinif)\n",
        "- 0-9 rakam tespiti"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# GPU kontrolu\n",
        "import tensorflow as tf\n",
        "print('TensorFlow:', tf.__version__)\n",
        "print('GPU:', tf.config.list_physical_devices('GPU'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Gerekli kutuphaneler\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, Model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Model ayarlari\n",
        "IMG_SIZE = 96\n",
        "GRID_SIZE = 6\n",
        "NUM_CLASSES = 10\n",
        "OUTPUT_PER_CELL = 5 + NUM_CLASSES  # 15\n",
        "\n",
        "# Egitim ayarlari - Guncellendi\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 150  # Arttirildi\n",
        "LEARNING_RATE = 0.0005  # Dusuruldu\n",
        "TRAIN_SAMPLES = 15000  # Arttirildi\n",
        "VAL_SAMPLES = 3000  # Arttirildi\n",
        "\n",
        "print(f'Grid: {GRID_SIZE}x{GRID_SIZE}, Output per cell: {OUTPUT_PER_CELL}')\n",
        "print(f'Train: {TRAIN_SAMPLES}, Val: {VAL_SAMPLES}, Epochs: {EPOCHS}, LR: {LEARNING_RATE}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# MNIST veri setini yukle\n",
        "from tensorflow.keras.datasets import mnist\n",
        "import cv2\n",
        "\n",
        "(mnist_x_train, mnist_y_train), (mnist_x_test, mnist_y_test) = mnist.load_data()\n",
        "print(f'MNIST Train: {mnist_x_train.shape}')\n",
        "print(f'MNIST Test: {mnist_x_test.shape}')\n",
        "\n",
        "# Her sinif icin ornekleri ayir (hizli erisim icin)\n",
        "mnist_by_class = {}\n",
        "for i in range(10):\n",
        "    mnist_by_class[i] = mnist_x_train[mnist_y_train == i]\n",
        "    print(f'  Sinif {i}: {len(mnist_by_class[i])} ornek')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_sample_mnist(img_size=96, max_digits=3):\n",
        "    \"\"\"MNIST rakamlari kullanarak goruntu ve YOLO etiket olusturur.\"\"\"\n",
        "    \n",
        "    # Arka plan (beyaz veya acik gri + hafif gurultu)\n",
        "    bg_color = random.randint(220, 255)\n",
        "    img = np.full((img_size, img_size), bg_color, dtype=np.uint8)\n",
        "    \n",
        "    # Hafif gurultu\n",
        "    noise = np.random.normal(0, 3, img.shape).astype(np.int16)\n",
        "    img = np.clip(img.astype(np.int16) + noise, 0, 255).astype(np.uint8)\n",
        "    \n",
        "    labels = []\n",
        "    num_digits = random.randint(1, max_digits)\n",
        "    occupied = []\n",
        "    \n",
        "    for _ in range(num_digits):\n",
        "        digit = random.randint(0, 9)\n",
        "        \n",
        "        # MNIST'ten rastgele bir rakam sec\n",
        "        mnist_idx = random.randint(0, len(mnist_by_class[digit]) - 1)\n",
        "        digit_img = mnist_by_class[digit][mnist_idx].copy()\n",
        "        \n",
        "        # Rastgele boyut (20-40 piksel)\n",
        "        new_size = random.randint(20, 40)\n",
        "        digit_img = cv2.resize(digit_img, (new_size, new_size), interpolation=cv2.INTER_AREA)\n",
        "        \n",
        "        # Rastgele donus (hafif)\n",
        "        angle = random.uniform(-15, 15)\n",
        "        M = cv2.getRotationMatrix2D((new_size/2, new_size/2), angle, 1.0)\n",
        "        digit_img = cv2.warpAffine(digit_img, M, (new_size, new_size), borderValue=0)\n",
        "        \n",
        "        # Cakismayan konum bul\n",
        "        margin = 3\n",
        "        for attempt in range(30):\n",
        "            x = random.randint(margin, img_size - new_size - margin)\n",
        "            y = random.randint(margin, img_size - new_size - margin)\n",
        "            \n",
        "            overlap = False\n",
        "            for ox, oy, ow, oh in occupied:\n",
        "                if (x < ox + ow + 2 and x + new_size > ox - 2 and \n",
        "                    y < oy + oh + 2 and y + new_size > oy - 2):\n",
        "                    overlap = True\n",
        "                    break\n",
        "            if not overlap:\n",
        "                break\n",
        "        \n",
        "        if overlap:\n",
        "            continue\n",
        "        \n",
        "        occupied.append((x, y, new_size, new_size))\n",
        "        \n",
        "        # Rakamin bounding box'ini bul (sifir olmayan pikseller)\n",
        "        coords = np.where(digit_img > 30)\n",
        "        if len(coords[0]) > 0:\n",
        "            y_min, y_max = coords[0].min(), coords[0].max()\n",
        "            x_min, x_max = coords[1].min(), coords[1].max()\n",
        "            actual_w = x_max - x_min + 1\n",
        "            actual_h = y_max - y_min + 1\n",
        "        else:\n",
        "            x_min, y_min = 0, 0\n",
        "            actual_w, actual_h = new_size, new_size\n",
        "        \n",
        "        # Rakam rengini tersle (MNIST siyah uzerine beyaz, biz beyaz uzerine siyah istiyoruz)\n",
        "        digit_inverted = 255 - digit_img\n",
        "        \n",
        "        # Rastgele yogunluk\n",
        "        intensity = random.uniform(0.7, 1.0)\n",
        "        digit_inverted = (digit_inverted * intensity).astype(np.uint8)\n",
        "        \n",
        "        # Goruntiye yerlestir (alpha blending)\n",
        "        for dy in range(new_size):\n",
        "            for dx in range(new_size):\n",
        "                if digit_img[dy, dx] > 30:  # Sadece rakam pikselleri\n",
        "                    alpha = digit_img[dy, dx] / 255.0\n",
        "                    img[y + dy, x + dx] = int(img[y + dy, x + dx] * (1 - alpha) + \n",
        "                                               digit_inverted[dy, dx] * alpha)\n",
        "        \n",
        "        # YOLO formati (normalize edilmis)\n",
        "        bbox_x = x + x_min\n",
        "        bbox_y = y + y_min\n",
        "        x_center = (bbox_x + actual_w / 2) / img_size\n",
        "        y_center = (bbox_y + actual_h / 2) / img_size\n",
        "        width = actual_w / img_size\n",
        "        height = actual_h / img_size\n",
        "        \n",
        "        # Sinirlari kontrol et\n",
        "        x_center = np.clip(x_center, 0, 1)\n",
        "        y_center = np.clip(y_center, 0, 1)\n",
        "        width = np.clip(width, 0.05, 1)\n",
        "        height = np.clip(height, 0.05, 1)\n",
        "        \n",
        "        labels.append([digit, x_center, y_center, width, height])\n",
        "    \n",
        "    # Grayscale'den RGB'ye\n",
        "    img_rgb = np.stack([img, img, img], axis=-1)\n",
        "    \n",
        "    # Rastgele parlaklik/kontrast\n",
        "    brightness = random.uniform(0.85, 1.15)\n",
        "    img_rgb = np.clip(img_rgb * brightness, 0, 255).astype(np.uint8)\n",
        "    \n",
        "    return img_rgb, labels\n",
        "\n",
        "def labels_to_yolo_output(labels, grid_size=6, num_classes=10):\n",
        "    \"\"\"YOLO etiketlerini grid formatina donusturur.\"\"\"\n",
        "    output = np.zeros((grid_size, grid_size, 5 + num_classes), dtype=np.float32)\n",
        "    \n",
        "    for label in labels:\n",
        "        class_id, x_center, y_center, width, height = label\n",
        "        grid_x = min(int(x_center * grid_size), grid_size - 1)\n",
        "        grid_y = min(int(y_center * grid_size), grid_size - 1)\n",
        "        \n",
        "        x_offset = x_center * grid_size - grid_x\n",
        "        y_offset = y_center * grid_size - grid_y\n",
        "        \n",
        "        if output[grid_y, grid_x, 4] == 0:\n",
        "            output[grid_y, grid_x, 0] = x_offset\n",
        "            output[grid_y, grid_x, 1] = y_offset\n",
        "            output[grid_y, grid_x, 2] = width\n",
        "            output[grid_y, grid_x, 3] = height\n",
        "            output[grid_y, grid_x, 4] = 1.0\n",
        "            output[grid_y, grid_x, 5 + int(class_id)] = 1.0\n",
        "    \n",
        "    return output\n",
        "\n",
        "print('Fonksiyonlar tanimlandi (MNIST tabanli).')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ornek MNIST goruntuleri goster\n",
        "fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
        "for ax in axes.flatten():\n",
        "    img, labels = generate_sample_mnist()\n",
        "    ax.imshow(img)\n",
        "    ax.axis('off')\n",
        "    for label in labels:\n",
        "        cls, xc, yc, w, h = label\n",
        "        x1 = int((xc - w/2) * IMG_SIZE)\n",
        "        y1 = int((yc - h/2) * IMG_SIZE)\n",
        "        rect = plt.Rectangle((x1, y1), int(w*IMG_SIZE), int(h*IMG_SIZE), fill=False, color='red', linewidth=2)\n",
        "        ax.add_patch(rect)\n",
        "        ax.text(x1, y1-2, str(int(cls)), color='red', fontsize=10, weight='bold')\n",
        "plt.suptitle('MNIST Tabanli Ornek Egitim Verileri')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# MNIST tabanli veri seti olustur\n",
        "print('Egitim verisi olusturuluyor (MNIST)...')\n",
        "X_train, y_train = [], []\n",
        "for i in range(TRAIN_SAMPLES):\n",
        "    if i % 2000 == 0: print(f'  {i}/{TRAIN_SAMPLES}')\n",
        "    img, labels = generate_sample_mnist(IMG_SIZE, max_digits=3)\n",
        "    X_train.append(img)\n",
        "    y_train.append(labels_to_yolo_output(labels, GRID_SIZE, NUM_CLASSES))\n",
        "\n",
        "X_train = np.array(X_train, dtype=np.float32) / 255.0\n",
        "y_train = np.array(y_train, dtype=np.float32)\n",
        "\n",
        "print('Validation verisi olusturuluyor (MNIST)...')\n",
        "X_val, y_val = [], []\n",
        "for i in range(VAL_SAMPLES):\n",
        "    if i % 500 == 0: print(f'  {i}/{VAL_SAMPLES}')\n",
        "    img, labels = generate_sample_mnist(IMG_SIZE, max_digits=3)\n",
        "    X_val.append(img)\n",
        "    y_val.append(labels_to_yolo_output(labels, GRID_SIZE, NUM_CLASSES))\n",
        "\n",
        "X_val = np.array(X_val, dtype=np.float32) / 255.0\n",
        "y_val = np.array(y_val, dtype=np.float32)\n",
        "\n",
        "print(f'X_train: {X_train.shape}, y_train: {y_train.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# MicroYOLO Model - Lambda layer olmadan\n",
        "class YOLOOutputLayer(layers.Layer):\n",
        "    \"\"\"YOLO ciktisi icin ozel aktivasyon layer'i\"\"\"\n",
        "    def __init__(self, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "    \n",
        "    def call(self, x):\n",
        "        # x shape: (batch, grid, grid, 15)\n",
        "        # [0:4] -> bbox (x, y, w, h) -> sigmoid\n",
        "        # [4] -> confidence -> sigmoid\n",
        "        # [5:15] -> classes -> softmax\n",
        "        bbox_conf = tf.sigmoid(x[..., :5])\n",
        "        classes = tf.nn.softmax(x[..., 5:])\n",
        "        return tf.concat([bbox_conf, classes], axis=-1)\n",
        "    \n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return input_shape\n",
        "\n",
        "def create_micro_yolo(input_shape=(96, 96, 3), grid_size=6, num_classes=10):\n",
        "    inputs = keras.Input(shape=input_shape)\n",
        "    \n",
        "    # Backbone - cok basit\n",
        "    x = layers.Conv2D(16, 3, padding='same', use_bias=False)(inputs)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.ReLU()(x)\n",
        "    x = layers.MaxPooling2D(2)(x)  # 48x48\n",
        "    \n",
        "    x = layers.Conv2D(32, 3, padding='same', use_bias=False)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.ReLU()(x)\n",
        "    x = layers.MaxPooling2D(2)(x)  # 24x24\n",
        "    \n",
        "    x = layers.Conv2D(64, 3, padding='same', use_bias=False)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.ReLU()(x)\n",
        "    x = layers.MaxPooling2D(2)(x)  # 12x12\n",
        "    \n",
        "    x = layers.Conv2D(128, 3, padding='same', use_bias=False)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.ReLU()(x)\n",
        "    x = layers.MaxPooling2D(2)(x)  # 6x6\n",
        "    \n",
        "    # Detection Head\n",
        "    x = layers.Conv2D(64, 1, padding='same', use_bias=False)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.ReLU()(x)\n",
        "    \n",
        "    output_channels = 5 + num_classes\n",
        "    x = layers.Conv2D(output_channels, 1, padding='same')(x)\n",
        "    \n",
        "    # Ozel YOLO aktivasyon layer'i\n",
        "    outputs = YOLOOutputLayer()(x)\n",
        "    \n",
        "    return Model(inputs, outputs, name='MicroYOLO')\n",
        "\n",
        "model = create_micro_yolo()\n",
        "model.summary()\n",
        "print(f'Toplam parametre: {model.count_params():,}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# YOLO Loss - Duzeltilmis (Cross-Entropy ile)\n",
        "def yolo_loss(y_true, y_pred):\n",
        "    obj_mask = y_true[..., 4:5]  # (batch, 6, 6, 1)\n",
        "    noobj_mask = 1.0 - obj_mask\n",
        "    \n",
        "    # Kayip agirliklari\n",
        "    lambda_coord = 5.0\n",
        "    lambda_noobj = 0.5\n",
        "    lambda_class = 1.0\n",
        "    \n",
        "    # Koordinat kaybi (MSE, sadece nesne olan hucrelerde)\n",
        "    xy_loss = tf.reduce_sum(obj_mask * tf.square(y_true[..., :2] - y_pred[..., :2]))\n",
        "    \n",
        "    # Boyut kaybi (sqrt ile)\n",
        "    wh_true = tf.sqrt(tf.abs(y_true[..., 2:4]) + 1e-6)\n",
        "    wh_pred = tf.sqrt(tf.abs(y_pred[..., 2:4]) + 1e-6)\n",
        "    wh_loss = tf.reduce_sum(obj_mask * tf.square(wh_true - wh_pred))\n",
        "    \n",
        "    # Confidence kaybi (Binary Cross-Entropy)\n",
        "    conf_pred = tf.clip_by_value(y_pred[..., 4:5], 1e-7, 1.0 - 1e-7)\n",
        "    conf_loss_obj = -tf.reduce_sum(obj_mask * tf.math.log(conf_pred))\n",
        "    conf_loss_noobj = -tf.reduce_sum(noobj_mask * tf.math.log(1.0 - conf_pred))\n",
        "    \n",
        "    # Sinif kaybi (Categorical Cross-Entropy, sadece nesne olan hucrelerde)\n",
        "    class_true = y_true[..., 5:]  # one-hot\n",
        "    class_pred = tf.clip_by_value(y_pred[..., 5:], 1e-7, 1.0 - 1e-7)  # softmax output\n",
        "    class_loss = -tf.reduce_sum(obj_mask * class_true * tf.math.log(class_pred))\n",
        "    \n",
        "    # Toplam kayip\n",
        "    total = (lambda_coord * (xy_loss + wh_loss) + \n",
        "             conf_loss_obj + lambda_noobj * conf_loss_noobj + \n",
        "             lambda_class * class_loss)\n",
        "    \n",
        "    return total / tf.cast(tf.shape(y_true)[0], tf.float32)\n",
        "\n",
        "model.compile(optimizer=keras.optimizers.Adam(learning_rate=LEARNING_RATE), loss=yolo_loss)\n",
        "print('Model derlendi (Cross-Entropy loss ile).')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Egitim\n",
        "callbacks = [\n",
        "    ModelCheckpoint('micro_yolo_best.keras', monitor='val_loss', save_best_only=True, verbose=1),\n",
        "    EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True, verbose=1),\n",
        "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6, verbose=1)\n",
        "]\n",
        "\n",
        "print('Egitim basliyor...')\n",
        "history = model.fit(X_train, y_train, validation_data=(X_val, y_val),\n",
        "                    batch_size=BATCH_SIZE, epochs=EPOCHS, callbacks=callbacks, verbose=1)\n",
        "\n",
        "# Grafik\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.plot(history.history['loss'], label='Train')\n",
        "plt.plot(history.history['val_loss'], label='Val')\n",
        "plt.xlabel('Epoch'); plt.ylabel('Loss'); plt.legend(); plt.grid(True)\n",
        "plt.title('Egitim Kaybi')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test - tahmin decode\n",
        "def decode_predictions(pred, conf_threshold=0.3, img_size=96, grid_size=6):\n",
        "    detections = []\n",
        "    for gy in range(grid_size):\n",
        "        for gx in range(grid_size):\n",
        "            conf = pred[gy, gx, 4]\n",
        "            if conf > conf_threshold:\n",
        "                x_offset, y_offset = pred[gy, gx, 0], pred[gy, gx, 1]\n",
        "                w, h = pred[gy, gx, 2], pred[gy, gx, 3]\n",
        "                \n",
        "                x_center = (gx + x_offset) / grid_size\n",
        "                y_center = (gy + y_offset) / grid_size\n",
        "                \n",
        "                x1 = int((x_center - w/2) * img_size)\n",
        "                y1 = int((y_center - h/2) * img_size)\n",
        "                x2 = int((x_center + w/2) * img_size)\n",
        "                y2 = int((y_center + h/2) * img_size)\n",
        "                \n",
        "                class_probs = pred[gy, gx, 5:]\n",
        "                class_id = np.argmax(class_probs)\n",
        "                final_conf = conf * class_probs[class_id]\n",
        "                \n",
        "                if final_conf > conf_threshold:\n",
        "                    detections.append([class_id, final_conf, x1, y1, x2, y2])\n",
        "    return detections\n",
        "\n",
        "# Sinif basina dogruluk hesapla\n",
        "print(\"Sinif basina test yapiliyor...\")\n",
        "class_correct = {i: 0 for i in range(10)}\n",
        "class_total = {i: 0 for i in range(10)}\n",
        "\n",
        "for _ in range(500):\n",
        "    img, labels = generate_sample_mnist(max_digits=1)  # Tek rakam\n",
        "    if len(labels) == 0:\n",
        "        continue\n",
        "    true_class = int(labels[0][0])\n",
        "    class_total[true_class] += 1\n",
        "    \n",
        "    pred = model.predict(np.expand_dims(img/255.0, 0), verbose=0)[0]\n",
        "    dets = decode_predictions(pred, 0.2)\n",
        "    \n",
        "    if len(dets) > 0:\n",
        "        pred_class = int(dets[0][0])\n",
        "        if pred_class == true_class:\n",
        "            class_correct[true_class] += 1\n",
        "\n",
        "print(\"\\nSinif Basina Dogruluk:\")\n",
        "for i in range(10):\n",
        "    if class_total[i] > 0:\n",
        "        acc = class_correct[i] / class_total[i] * 100\n",
        "        print(f\"  Rakam {i}: {class_correct[i]}/{class_total[i]} = {acc:.1f}%\")\n",
        "\n",
        "# MNIST test goster\n",
        "fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
        "for ax in axes.flatten():\n",
        "    img, labels = generate_sample_mnist()\n",
        "    pred = model.predict(np.expand_dims(img/255.0, 0), verbose=0)[0]\n",
        "    dets = decode_predictions(pred, 0.3)\n",
        "    ax.imshow(img); ax.axis('off')\n",
        "    \n",
        "    # Gercek etiketler (yesil)\n",
        "    for label in labels:\n",
        "        cls, xc, yc, w, h = label\n",
        "        x1 = int((xc - w/2) * IMG_SIZE)\n",
        "        y1 = int((yc - h/2) * IMG_SIZE)\n",
        "        rect = plt.Rectangle((x1, y1), int(w*IMG_SIZE), int(h*IMG_SIZE), \n",
        "                              fill=False, color='green', linewidth=1, linestyle='--')\n",
        "        ax.add_patch(rect)\n",
        "    \n",
        "    # Tahminler (kirmizi)\n",
        "    for det in dets:\n",
        "        cls, conf, x1, y1, x2, y2 = det\n",
        "        rect = plt.Rectangle((x1, y1), x2-x1, y2-y1, fill=False, color='red', linewidth=2)\n",
        "        ax.add_patch(rect)\n",
        "        ax.text(x1, y1-2, f'{cls}:{conf:.0%}', color='red', fontsize=9, weight='bold')\n",
        "plt.suptitle('Yesil=Gercek, Kirmizi=Tahmin')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TFLite donusumu - Daha iyi quantization\n",
        "model = keras.models.load_model('micro_yolo_best.keras', \n",
        "                                 custom_objects={'yolo_loss': yolo_loss, 'YOLOOutputLayer': YOLOOutputLayer})\n",
        "\n",
        "# Daha kapsamli representative dataset (her siniftan esit ornek)\n",
        "def representative_dataset_balanced():\n",
        "    \"\"\"Her siniftan esit sayida ornek iceren representative dataset\"\"\"\n",
        "    samples_per_class = 100\n",
        "    for digit in range(10):\n",
        "        for _ in range(samples_per_class):\n",
        "            # Tek rakamli goruntu olustur\n",
        "            img = np.full((IMG_SIZE, IMG_SIZE), random.randint(220, 255), dtype=np.uint8)\n",
        "            mnist_digit = random.choice(mnist_by_class[digit])\n",
        "            \n",
        "            # Rasgele konum ve boyut\n",
        "            scale = random.uniform(0.3, 0.6)\n",
        "            new_h = int(28 * scale * IMG_SIZE / 28)\n",
        "            new_w = new_h\n",
        "            \n",
        "            digit_resized = cv2.resize(mnist_digit, (new_w, new_h))\n",
        "            digit_resized = 255 - digit_resized  # Invert\n",
        "            \n",
        "            max_x = IMG_SIZE - new_w\n",
        "            max_y = IMG_SIZE - new_h\n",
        "            x = random.randint(0, max(0, max_x))\n",
        "            y = random.randint(0, max(0, max_y))\n",
        "            \n",
        "            # Blend\n",
        "            roi = img[y:y+new_h, x:x+new_w]\n",
        "            mask = digit_resized.astype(np.float32) / 255.0\n",
        "            blended = (roi * (1 - mask) + 0 * mask).astype(np.uint8)\n",
        "            img[y:y+new_h, x:x+new_w] = blended\n",
        "            \n",
        "            # RGB'ye cevir ve normalize et\n",
        "            img_rgb = np.stack([img, img, img], axis=-1).astype(np.float32) / 255.0\n",
        "            yield [np.expand_dims(img_rgb, 0)]\n",
        "\n",
        "# INT8 Quantization\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.representative_dataset = representative_dataset_balanced\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "converter.inference_input_type = tf.int8\n",
        "converter.inference_output_type = tf.int8\n",
        "\n",
        "print('TFLite donusumu (INT8 - dengeli dataset)...')\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "with open('micro_yolo_int8.tflite', 'wb') as f:\n",
        "    f.write(tflite_model)\n",
        "\n",
        "print(f'TFLite model: {len(tflite_model) / 1024:.1f} KB')\n",
        "\n",
        "# ========== INT8 MODEL DOGRULAMA ==========\n",
        "print('\\n--- INT8 Model Test ---')\n",
        "interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "print(f'Input: {input_details[0][\"shape\"]}, dtype={input_details[0][\"dtype\"]}')\n",
        "print(f'Output: {output_details[0][\"shape\"]}, dtype={output_details[0][\"dtype\"]}')\n",
        "\n",
        "# Her sinif icin test\n",
        "int8_correct = {i: 0 for i in range(10)}\n",
        "int8_total = {i: 0 for i in range(10)}\n",
        "\n",
        "input_scale = input_details[0]['quantization'][0]\n",
        "input_zp = input_details[0]['quantization'][1]\n",
        "output_scale = output_details[0]['quantization'][0]\n",
        "output_zp = output_details[0]['quantization'][1]\n",
        "\n",
        "print(f'Input quant: scale={input_scale}, zp={input_zp}')\n",
        "print(f'Output quant: scale={output_scale}, zp={output_zp}')\n",
        "\n",
        "for digit in range(10):\n",
        "    for _ in range(30):\n",
        "        img, labels = generate_sample_mnist(max_digits=1)\n",
        "        if len(labels) == 0:\n",
        "            continue\n",
        "        \n",
        "        # img 2D (96,96) olmali\n",
        "        if len(img.shape) == 2:\n",
        "            img_rgb = np.stack([img, img, img], axis=-1)  # (96, 96, 3)\n",
        "        else:\n",
        "            img_rgb = img  # zaten 3D ise\n",
        "        \n",
        "        # Normalize ve quantize\n",
        "        img_float = img_rgb.astype(np.float32) / 255.0\n",
        "        img_int8 = ((img_float / input_scale) + input_zp).astype(np.int8)\n",
        "        \n",
        "        # Batch dimension ekle: (96,96,3) -> (1,96,96,3)\n",
        "        input_data = img_int8.reshape(1, 96, 96, 3)\n",
        "        \n",
        "        interpreter.set_tensor(input_details[0]['index'], input_data)\n",
        "        interpreter.invoke()\n",
        "        \n",
        "        output = interpreter.get_tensor(output_details[0]['index'])[0]\n",
        "        output_scale = output_details[0]['quantization'][0]\n",
        "        output_zp = output_details[0]['quantization'][1]\n",
        "        output_float = (output.astype(np.float32) - output_zp) * output_scale\n",
        "        \n",
        "        # En yuksek confidence'li hucreyi bul\n",
        "        best_conf = -1\n",
        "        best_cls = -1\n",
        "        for gy in range(6):\n",
        "            for gx in range(6):\n",
        "                conf = output_float[gy, gx, 4]\n",
        "                if conf > best_conf:\n",
        "                    best_conf = conf\n",
        "                    class_probs = output_float[gy, gx, 5:15]\n",
        "                    best_cls = np.argmax(class_probs)\n",
        "        \n",
        "        true_cls = int(labels[0][0])\n",
        "        int8_total[true_cls] += 1\n",
        "        if best_cls == true_cls:\n",
        "            int8_correct[true_cls] += 1\n",
        "\n",
        "print('\\nINT8 Model Sinif Basina Dogruluk:')\n",
        "for i in range(10):\n",
        "    if int8_total[i] > 0:\n",
        "        acc = int8_correct[i] / int8_total[i] * 100\n",
        "        print(f'  Rakam {i}: {int8_correct[i]}/{int8_total[i]} = {acc:.1f}%')\n",
        "\n",
        "# Bilgileri goster\n",
        "interp = tf.lite.Interpreter(model_path='micro_yolo_int8.tflite')\n",
        "interp.allocate_tensors()\n",
        "inp = interp.get_input_details()[0]\n",
        "out = interp.get_output_details()[0]\n",
        "print(f\"Input: {inp['shape']}, scale={inp['quantization'][0]:.6f}, zp={inp['quantization'][1]}\")\n",
        "print(f\"Output: {out['shape']}, scale={out['quantization'][0]:.6f}, zp={out['quantization'][1]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# C Header dosyasi olustur\n",
        "def create_c_header(tflite_path, header_path):\n",
        "    with open(tflite_path, 'rb') as f:\n",
        "        data = f.read()\n",
        "    \n",
        "    interp = tf.lite.Interpreter(model_path=tflite_path)\n",
        "    interp.allocate_tensors()\n",
        "    inp = interp.get_input_details()[0]\n",
        "    out = interp.get_output_details()[0]\n",
        "    \n",
        "    with open(header_path, 'w') as f:\n",
        "        f.write('// MicroYOLO for ESP32-CAM - Auto-generated\\n')\n",
        "        f.write(f'// Model size: {len(data)} bytes\\n\\n')\n",
        "        f.write('#ifndef MICRO_YOLO_MODEL_H\\n#define MICRO_YOLO_MODEL_H\\n\\n')\n",
        "        f.write('#include <stdint.h>\\n\\n')\n",
        "        \n",
        "        f.write('// Sabitler\\n')\n",
        "        f.write('#define MICRO_YOLO_INPUT_SIZE 96\\n')\n",
        "        f.write('#define MICRO_YOLO_GRID_SIZE 6\\n')\n",
        "        f.write('#define MICRO_YOLO_NUM_CLASSES 10\\n\\n')\n",
        "        \n",
        "        f.write('// Quantization\\n')\n",
        "        f.write(f'const float input_scale = {inp[\"quantization\"][0]}f;\\n')\n",
        "        f.write(f'const int input_zero_point = {inp[\"quantization\"][1]};\\n')\n",
        "        f.write(f'const float output_scale = {out[\"quantization\"][0]}f;\\n')\n",
        "        f.write(f'const int output_zero_point = {out[\"quantization\"][1]};\\n\\n')\n",
        "        \n",
        "        f.write('const char* digit_labels[] = {\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\"};\\n')\n",
        "        f.write('const int NUM_CLASSES = 10;\\n\\n')\n",
        "        \n",
        "        f.write(f'const unsigned int digit_model_len = {len(data)};\\n')\n",
        "        f.write('alignas(8) const unsigned char digit_model[] = {\\n')\n",
        "        \n",
        "        for i, byte in enumerate(data):\n",
        "            if i % 16 == 0: f.write('  ')\n",
        "            f.write(f'0x{byte:02x},')\n",
        "            if i % 16 == 15: f.write('\\n')\n",
        "        \n",
        "        f.write('\\n};\\n\\n#endif\\n')\n",
        "    \n",
        "    print(f'Header: {header_path} ({len(data)/1024:.1f} KB)')\n",
        "\n",
        "create_c_header('micro_yolo_int8.tflite', 'micro_yolo_model.h')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Dosyalari indir\n",
        "from google.colab import files\n",
        "print('Dosyalar indiriliyor...')\n",
        "files.download('micro_yolo_model.h')\n",
        "files.download('micro_yolo_int8.tflite')\n",
        "print('Tamamlandi! micro_yolo_model.h dosyasini ESP32 projesine kopyala.')"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
